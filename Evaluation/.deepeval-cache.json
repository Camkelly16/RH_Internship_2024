{"test_cases_lookup_map": {"{\"actual_output\": \"A. rate(http_requests_total[1m])\\n\\nThe `rate()` function calculates the rate of a metric over a given time window. In this case, it calculates the rate of HTTP requests over the last 1 minute.\", \"context\": null, \"expected_output\": \"rate(http_requests_total[1m])\", \"hyperparameters\": null, \"input\": \"What PromQL expression calculates the rate of HTTP requests over the last 1 minute?\", \"retrieval_context\": [\"\"]}": {"cached_metrics_data": [{"metric_metadata": {"metric": "Answer Relevancy", "threshold": 0.5, "success": true, "score": 1.0, "reason": "The score is 1.00 because the provided input is directly answered by the given PromQL expression.", "strictMode": false, "evaluationModel": "gemma", "evaluationCost": 0}, "metric_configuration": {"threshold": 0.5, "evaluation_model": "gemma", "strict_mode": false, "include_reason": true}}, {"metric_metadata": {"metric": "Faithfulness", "threshold": 0.5, "success": true, "score": 0.5, "reason": "The faithfulness score is 0.50 because the actual output contradicts the retrieval context as it claims the provided context includes HTTP requests, which is not reflected in the given information.", "strictMode": false, "evaluationModel": "gemma", "evaluationCost": 0}, "metric_configuration": {"threshold": 0.5, "evaluation_model": "gemma", "strict_mode": false, "include_reason": true}}]}}}